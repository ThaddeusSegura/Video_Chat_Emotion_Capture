{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "realtime_emotion.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Xa8Z49PFzyTk",
        "LPOtFIvB0BOn",
        "75EbY6tf0XqF",
        "iYMFoelY0vFl"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVul1r7CzY_9",
        "colab_type": "text"
      },
      "source": [
        "# Real Time Video Emotion Recognition\n",
        "\n",
        "This notebook will go through training a simple model to classify the emotions on someone's face.\n",
        "\n",
        "This model is loaded by a script that will monitor these emotions in real time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa8Z49PFzyTk",
        "colab_type": "text"
      },
      "source": [
        "### 1) General Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN1sqLpV1bqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1e53df5-fc21-4677-9d19-61e908e53f15"
      },
      "source": [
        "# mount drive to colab.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0EHodtVtvto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Imports \n",
        "\n",
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPOtFIvB0BOn",
        "colab_type": "text"
      },
      "source": [
        "### 2) Load and Transform Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM6bMQULvf77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "64678093-1930-40ff-9bb3-fcebc03c9ab4"
      },
      "source": [
        "#load data and look at the df.\n",
        "\n",
        "df=pd.read_csv('gdrive/My Drive/fer2013.csv')\n",
        "\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   emotion                                             pixels     Usage\n",
            "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
            "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
            "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
            "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
            "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbDwT51lyUJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build the training and test sets \n",
        "X_train,train_y,X_test,test_y=[],[],[],[]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzu_bqqnzxRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set hyperparameters and preprocess data.\n",
        "\n",
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 200\n",
        "width, height = 48, 48\n",
        "\n",
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')\n",
        "\n",
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZH62scTz0kc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65d72d35-e685-4942-c48a-9f2d9e007d57"
      },
      "source": [
        "#normalizing data between 0 and 1\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
        "\n",
        "print(f\"shape:{X_train.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape:(28709, 48, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75EbY6tf0XqF",
        "colab_type": "text"
      },
      "source": [
        "### 3) Build and train CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbrkxkK1LvY0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "755f2c6a-318a-4827-868a-a193c5db0990"
      },
      "source": [
        "##designing the cnn\n",
        "#1st convolution layer\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
        "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#3rd convolution layer\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_55 (Conv2D)           (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 44, 44, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 20, 20, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 18, 18, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 5, 5, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 7)                 7175      \n",
            "=================================================================\n",
            "Total params: 3,250,631\n",
            "Trainable params: 3,250,631\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAduNbj50UAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compliling the model\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5zNNV2f1mo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc175db1-b099-4d74-8fc9-d8d758cc2773"
      },
      "source": [
        "#Training the model\n",
        "model.fit(X_train, train_y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, test_y),\n",
        "          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "449/449 [==============================] - 7s 15ms/step - loss: 1.7546 - accuracy: 0.2758 - val_loss: 1.5643 - val_accuracy: 0.3934\n",
            "Epoch 2/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.5019 - accuracy: 0.4091 - val_loss: 1.4380 - val_accuracy: 0.4586\n",
            "Epoch 3/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.3759 - accuracy: 0.4699 - val_loss: 1.2973 - val_accuracy: 0.4960\n",
            "Epoch 4/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.3080 - accuracy: 0.4981 - val_loss: 1.2592 - val_accuracy: 0.5127\n",
            "Epoch 5/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.2579 - accuracy: 0.5183 - val_loss: 1.2332 - val_accuracy: 0.5297\n",
            "Epoch 6/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.2157 - accuracy: 0.5337 - val_loss: 1.1837 - val_accuracy: 0.5419\n",
            "Epoch 7/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.1807 - accuracy: 0.5486 - val_loss: 1.1788 - val_accuracy: 0.5525\n",
            "Epoch 8/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.1574 - accuracy: 0.5559 - val_loss: 1.1627 - val_accuracy: 0.5570\n",
            "Epoch 9/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.1256 - accuracy: 0.5677 - val_loss: 1.1388 - val_accuracy: 0.5626\n",
            "Epoch 10/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.1008 - accuracy: 0.5810 - val_loss: 1.1507 - val_accuracy: 0.5634\n",
            "Epoch 11/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.0786 - accuracy: 0.5886 - val_loss: 1.1455 - val_accuracy: 0.5651\n",
            "Epoch 12/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.0536 - accuracy: 0.5979 - val_loss: 1.1504 - val_accuracy: 0.5634\n",
            "Epoch 13/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.0298 - accuracy: 0.6081 - val_loss: 1.1274 - val_accuracy: 0.5734\n",
            "Epoch 14/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 1.0089 - accuracy: 0.6144 - val_loss: 1.1232 - val_accuracy: 0.5690\n",
            "Epoch 15/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.9834 - accuracy: 0.6244 - val_loss: 1.1275 - val_accuracy: 0.5851\n",
            "Epoch 16/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.9603 - accuracy: 0.6344 - val_loss: 1.1439 - val_accuracy: 0.5782\n",
            "Epoch 17/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.9375 - accuracy: 0.6400 - val_loss: 1.1500 - val_accuracy: 0.5793\n",
            "Epoch 18/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.9210 - accuracy: 0.6520 - val_loss: 1.1501 - val_accuracy: 0.5720\n",
            "Epoch 19/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.9067 - accuracy: 0.6547 - val_loss: 1.1373 - val_accuracy: 0.5851\n",
            "Epoch 20/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.8738 - accuracy: 0.6675 - val_loss: 1.1721 - val_accuracy: 0.5776\n",
            "Epoch 21/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.8554 - accuracy: 0.6750 - val_loss: 1.1610 - val_accuracy: 0.5876\n",
            "Epoch 22/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.8415 - accuracy: 0.6809 - val_loss: 1.1670 - val_accuracy: 0.5801\n",
            "Epoch 23/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.8243 - accuracy: 0.6881 - val_loss: 1.1781 - val_accuracy: 0.5896\n",
            "Epoch 24/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.8057 - accuracy: 0.6966 - val_loss: 1.2012 - val_accuracy: 0.5807\n",
            "Epoch 25/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.7805 - accuracy: 0.7045 - val_loss: 1.2157 - val_accuracy: 0.5924\n",
            "Epoch 26/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.7716 - accuracy: 0.7091 - val_loss: 1.2043 - val_accuracy: 0.5759\n",
            "Epoch 27/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.7559 - accuracy: 0.7127 - val_loss: 1.2504 - val_accuracy: 0.5826\n",
            "Epoch 28/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.7278 - accuracy: 0.7239 - val_loss: 1.2433 - val_accuracy: 0.5865\n",
            "Epoch 29/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.7136 - accuracy: 0.7332 - val_loss: 1.2309 - val_accuracy: 0.5882\n",
            "Epoch 30/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.7008 - accuracy: 0.7377 - val_loss: 1.2607 - val_accuracy: 0.5770\n",
            "Epoch 31/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.6783 - accuracy: 0.7449 - val_loss: 1.3241 - val_accuracy: 0.5887\n",
            "Epoch 32/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.6740 - accuracy: 0.7466 - val_loss: 1.3354 - val_accuracy: 0.5837\n",
            "Epoch 33/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.6645 - accuracy: 0.7531 - val_loss: 1.3196 - val_accuracy: 0.5751\n",
            "Epoch 34/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.6419 - accuracy: 0.7610 - val_loss: 1.3453 - val_accuracy: 0.5723\n",
            "Epoch 35/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.6344 - accuracy: 0.7659 - val_loss: 1.3699 - val_accuracy: 0.5929\n",
            "Epoch 36/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.6130 - accuracy: 0.7705 - val_loss: 1.3656 - val_accuracy: 0.5929\n",
            "Epoch 37/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.6058 - accuracy: 0.7756 - val_loss: 1.3608 - val_accuracy: 0.5823\n",
            "Epoch 38/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.6052 - accuracy: 0.7754 - val_loss: 1.3430 - val_accuracy: 0.5787\n",
            "Epoch 39/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.5960 - accuracy: 0.7777 - val_loss: 1.3380 - val_accuracy: 0.5676\n",
            "Epoch 40/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.5874 - accuracy: 0.7847 - val_loss: 1.3349 - val_accuracy: 0.5901\n",
            "Epoch 41/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.5626 - accuracy: 0.7911 - val_loss: 1.4136 - val_accuracy: 0.5821\n",
            "Epoch 42/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.5587 - accuracy: 0.7960 - val_loss: 1.4133 - val_accuracy: 0.5949\n",
            "Epoch 43/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.5430 - accuracy: 0.8024 - val_loss: 1.4341 - val_accuracy: 0.6010\n",
            "Epoch 44/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.5391 - accuracy: 0.8020 - val_loss: 1.4853 - val_accuracy: 0.5893\n",
            "Epoch 45/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.5310 - accuracy: 0.8088 - val_loss: 1.5020 - val_accuracy: 0.5729\n",
            "Epoch 46/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.5222 - accuracy: 0.8101 - val_loss: 1.5304 - val_accuracy: 0.5915\n",
            "Epoch 47/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.5130 - accuracy: 0.8124 - val_loss: 1.4685 - val_accuracy: 0.5868\n",
            "Epoch 48/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.5061 - accuracy: 0.8169 - val_loss: 1.4722 - val_accuracy: 0.5924\n",
            "Epoch 49/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4950 - accuracy: 0.8228 - val_loss: 1.4461 - val_accuracy: 0.5698\n",
            "Epoch 50/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4888 - accuracy: 0.8235 - val_loss: 1.5646 - val_accuracy: 0.5779\n",
            "Epoch 51/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4837 - accuracy: 0.8262 - val_loss: 1.5664 - val_accuracy: 0.5770\n",
            "Epoch 52/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4694 - accuracy: 0.8285 - val_loss: 1.5930 - val_accuracy: 0.5776\n",
            "Epoch 53/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4763 - accuracy: 0.8291 - val_loss: 1.5415 - val_accuracy: 0.5801\n",
            "Epoch 54/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4667 - accuracy: 0.8310 - val_loss: 1.5187 - val_accuracy: 0.5737\n",
            "Epoch 55/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4707 - accuracy: 0.8320 - val_loss: 1.5923 - val_accuracy: 0.5748\n",
            "Epoch 56/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4500 - accuracy: 0.8423 - val_loss: 1.4774 - val_accuracy: 0.5776\n",
            "Epoch 57/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4446 - accuracy: 0.8428 - val_loss: 1.6196 - val_accuracy: 0.5795\n",
            "Epoch 58/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4413 - accuracy: 0.8425 - val_loss: 1.5731 - val_accuracy: 0.5784\n",
            "Epoch 59/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4344 - accuracy: 0.8462 - val_loss: 1.5557 - val_accuracy: 0.5840\n",
            "Epoch 60/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4262 - accuracy: 0.8473 - val_loss: 1.6013 - val_accuracy: 0.5887\n",
            "Epoch 61/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4183 - accuracy: 0.8504 - val_loss: 1.6013 - val_accuracy: 0.5701\n",
            "Epoch 62/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4125 - accuracy: 0.8531 - val_loss: 1.6403 - val_accuracy: 0.5860\n",
            "Epoch 63/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4102 - accuracy: 0.8573 - val_loss: 1.6204 - val_accuracy: 0.5887\n",
            "Epoch 64/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3946 - accuracy: 0.8576 - val_loss: 1.6777 - val_accuracy: 0.5701\n",
            "Epoch 65/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.4203 - accuracy: 0.8529 - val_loss: 1.6537 - val_accuracy: 0.5734\n",
            "Epoch 66/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3997 - accuracy: 0.8568 - val_loss: 1.7276 - val_accuracy: 0.5843\n",
            "Epoch 67/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3933 - accuracy: 0.8620 - val_loss: 1.6461 - val_accuracy: 0.5837\n",
            "Epoch 68/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3900 - accuracy: 0.8615 - val_loss: 1.6016 - val_accuracy: 0.5779\n",
            "Epoch 69/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3933 - accuracy: 0.8614 - val_loss: 1.6410 - val_accuracy: 0.5946\n",
            "Epoch 70/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3827 - accuracy: 0.8647 - val_loss: 1.6779 - val_accuracy: 0.5857\n",
            "Epoch 71/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3861 - accuracy: 0.8648 - val_loss: 1.6806 - val_accuracy: 0.5862\n",
            "Epoch 72/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3754 - accuracy: 0.8681 - val_loss: 1.7362 - val_accuracy: 0.5857\n",
            "Epoch 73/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3817 - accuracy: 0.8682 - val_loss: 1.6859 - val_accuracy: 0.5871\n",
            "Epoch 74/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3703 - accuracy: 0.8706 - val_loss: 1.7688 - val_accuracy: 0.5756\n",
            "Epoch 75/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3795 - accuracy: 0.8675 - val_loss: 1.7034 - val_accuracy: 0.5851\n",
            "Epoch 76/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3593 - accuracy: 0.8741 - val_loss: 1.7639 - val_accuracy: 0.5812\n",
            "Epoch 77/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3390 - accuracy: 0.8822 - val_loss: 1.8505 - val_accuracy: 0.5854\n",
            "Epoch 78/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3477 - accuracy: 0.8797 - val_loss: 1.8207 - val_accuracy: 0.5812\n",
            "Epoch 79/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3604 - accuracy: 0.8776 - val_loss: 1.6426 - val_accuracy: 0.5857\n",
            "Epoch 80/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3580 - accuracy: 0.8764 - val_loss: 1.8210 - val_accuracy: 0.5826\n",
            "Epoch 81/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3490 - accuracy: 0.8809 - val_loss: 1.7824 - val_accuracy: 0.5737\n",
            "Epoch 82/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3464 - accuracy: 0.8805 - val_loss: 1.7511 - val_accuracy: 0.5812\n",
            "Epoch 83/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3470 - accuracy: 0.8824 - val_loss: 1.7309 - val_accuracy: 0.5823\n",
            "Epoch 84/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3344 - accuracy: 0.8837 - val_loss: 1.8082 - val_accuracy: 0.5779\n",
            "Epoch 85/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3346 - accuracy: 0.8856 - val_loss: 1.7511 - val_accuracy: 0.5826\n",
            "Epoch 86/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3355 - accuracy: 0.8849 - val_loss: 1.8367 - val_accuracy: 0.5801\n",
            "Epoch 87/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3482 - accuracy: 0.8812 - val_loss: 1.7751 - val_accuracy: 0.5754\n",
            "Epoch 88/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3348 - accuracy: 0.8841 - val_loss: 1.7363 - val_accuracy: 0.5885\n",
            "Epoch 89/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3230 - accuracy: 0.8905 - val_loss: 1.8512 - val_accuracy: 0.5731\n",
            "Epoch 90/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3243 - accuracy: 0.8878 - val_loss: 1.9794 - val_accuracy: 0.5670\n",
            "Epoch 91/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3211 - accuracy: 0.8902 - val_loss: 1.8762 - val_accuracy: 0.5809\n",
            "Epoch 92/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3217 - accuracy: 0.8889 - val_loss: 1.8306 - val_accuracy: 0.5834\n",
            "Epoch 93/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3148 - accuracy: 0.8925 - val_loss: 1.7937 - val_accuracy: 0.5720\n",
            "Epoch 94/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3195 - accuracy: 0.8925 - val_loss: 1.8025 - val_accuracy: 0.5809\n",
            "Epoch 95/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3163 - accuracy: 0.8928 - val_loss: 1.8187 - val_accuracy: 0.5779\n",
            "Epoch 96/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3156 - accuracy: 0.8928 - val_loss: 1.7880 - val_accuracy: 0.5717\n",
            "Epoch 97/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3057 - accuracy: 0.8947 - val_loss: 1.7885 - val_accuracy: 0.5848\n",
            "Epoch 98/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3085 - accuracy: 0.8958 - val_loss: 1.9829 - val_accuracy: 0.5770\n",
            "Epoch 99/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3167 - accuracy: 0.8947 - val_loss: 1.8927 - val_accuracy: 0.5790\n",
            "Epoch 100/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3039 - accuracy: 0.8984 - val_loss: 1.9824 - val_accuracy: 0.5801\n",
            "Epoch 101/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3160 - accuracy: 0.8953 - val_loss: 1.8119 - val_accuracy: 0.5890\n",
            "Epoch 102/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3019 - accuracy: 0.8985 - val_loss: 1.8967 - val_accuracy: 0.5784\n",
            "Epoch 103/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3033 - accuracy: 0.8948 - val_loss: 1.9664 - val_accuracy: 0.5812\n",
            "Epoch 104/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2948 - accuracy: 0.9009 - val_loss: 1.8754 - val_accuracy: 0.5829\n",
            "Epoch 105/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2989 - accuracy: 0.9012 - val_loss: 1.8819 - val_accuracy: 0.5770\n",
            "Epoch 106/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2984 - accuracy: 0.9009 - val_loss: 1.8406 - val_accuracy: 0.5754\n",
            "Epoch 107/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3076 - accuracy: 0.8954 - val_loss: 1.8863 - val_accuracy: 0.5832\n",
            "Epoch 108/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2873 - accuracy: 0.9033 - val_loss: 1.9356 - val_accuracy: 0.5801\n",
            "Epoch 109/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2993 - accuracy: 0.8991 - val_loss: 1.8647 - val_accuracy: 0.5762\n",
            "Epoch 110/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3000 - accuracy: 0.9002 - val_loss: 1.9667 - val_accuracy: 0.5776\n",
            "Epoch 111/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2822 - accuracy: 0.9068 - val_loss: 2.1564 - val_accuracy: 0.5773\n",
            "Epoch 112/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3004 - accuracy: 0.9011 - val_loss: 1.8765 - val_accuracy: 0.5818\n",
            "Epoch 113/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2928 - accuracy: 0.9021 - val_loss: 1.8926 - val_accuracy: 0.5804\n",
            "Epoch 114/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2765 - accuracy: 0.9076 - val_loss: 1.7882 - val_accuracy: 0.5795\n",
            "Epoch 115/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2876 - accuracy: 0.9043 - val_loss: 1.8105 - val_accuracy: 0.5798\n",
            "Epoch 116/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2912 - accuracy: 0.9031 - val_loss: 1.8526 - val_accuracy: 0.5790\n",
            "Epoch 117/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2884 - accuracy: 0.9032 - val_loss: 1.8997 - val_accuracy: 0.5684\n",
            "Epoch 118/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2837 - accuracy: 0.9045 - val_loss: 1.9343 - val_accuracy: 0.5787\n",
            "Epoch 119/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2780 - accuracy: 0.9069 - val_loss: 1.9686 - val_accuracy: 0.5734\n",
            "Epoch 120/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2856 - accuracy: 0.9023 - val_loss: 1.9221 - val_accuracy: 0.5784\n",
            "Epoch 121/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2776 - accuracy: 0.9067 - val_loss: 2.0103 - val_accuracy: 0.5715\n",
            "Epoch 122/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2800 - accuracy: 0.9078 - val_loss: 1.9937 - val_accuracy: 0.5768\n",
            "Epoch 123/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2752 - accuracy: 0.9107 - val_loss: 1.9702 - val_accuracy: 0.5865\n",
            "Epoch 124/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2718 - accuracy: 0.9101 - val_loss: 1.8721 - val_accuracy: 0.5690\n",
            "Epoch 125/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2806 - accuracy: 0.9080 - val_loss: 1.8990 - val_accuracy: 0.5887\n",
            "Epoch 126/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2655 - accuracy: 0.9140 - val_loss: 1.9609 - val_accuracy: 0.5801\n",
            "Epoch 127/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.3039 - accuracy: 0.9031 - val_loss: 1.8825 - val_accuracy: 0.5759\n",
            "Epoch 128/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2724 - accuracy: 0.9113 - val_loss: 2.0850 - val_accuracy: 0.5756\n",
            "Epoch 129/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2696 - accuracy: 0.9135 - val_loss: 2.0922 - val_accuracy: 0.5695\n",
            "Epoch 130/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2730 - accuracy: 0.9095 - val_loss: 1.9690 - val_accuracy: 0.5637\n",
            "Epoch 131/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2691 - accuracy: 0.9119 - val_loss: 2.0633 - val_accuracy: 0.5690\n",
            "Epoch 132/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2696 - accuracy: 0.9130 - val_loss: 2.0045 - val_accuracy: 0.5745\n",
            "Epoch 133/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2597 - accuracy: 0.9150 - val_loss: 2.1087 - val_accuracy: 0.5815\n",
            "Epoch 134/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2838 - accuracy: 0.9085 - val_loss: 1.9761 - val_accuracy: 0.5639\n",
            "Epoch 135/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2627 - accuracy: 0.9137 - val_loss: 1.9521 - val_accuracy: 0.5773\n",
            "Epoch 136/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2648 - accuracy: 0.9130 - val_loss: 2.0508 - val_accuracy: 0.5756\n",
            "Epoch 137/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2666 - accuracy: 0.9121 - val_loss: 2.0084 - val_accuracy: 0.5726\n",
            "Epoch 138/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2578 - accuracy: 0.9172 - val_loss: 1.9812 - val_accuracy: 0.5709\n",
            "Epoch 139/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2553 - accuracy: 0.9168 - val_loss: 1.9313 - val_accuracy: 0.5756\n",
            "Epoch 140/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2620 - accuracy: 0.9150 - val_loss: 2.0017 - val_accuracy: 0.5737\n",
            "Epoch 141/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2616 - accuracy: 0.9129 - val_loss: 2.1365 - val_accuracy: 0.5706\n",
            "Epoch 142/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2806 - accuracy: 0.9095 - val_loss: 1.9221 - val_accuracy: 0.5729\n",
            "Epoch 143/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2530 - accuracy: 0.9172 - val_loss: 2.0441 - val_accuracy: 0.5704\n",
            "Epoch 144/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2553 - accuracy: 0.9190 - val_loss: 2.0615 - val_accuracy: 0.5748\n",
            "Epoch 145/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2743 - accuracy: 0.9101 - val_loss: 1.9060 - val_accuracy: 0.5692\n",
            "Epoch 146/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2581 - accuracy: 0.9173 - val_loss: 2.0131 - val_accuracy: 0.5740\n",
            "Epoch 147/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2660 - accuracy: 0.9164 - val_loss: 1.9591 - val_accuracy: 0.5695\n",
            "Epoch 148/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2606 - accuracy: 0.9159 - val_loss: 2.0251 - val_accuracy: 0.5737\n",
            "Epoch 149/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2496 - accuracy: 0.9192 - val_loss: 2.0888 - val_accuracy: 0.5823\n",
            "Epoch 150/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2566 - accuracy: 0.9174 - val_loss: 2.0281 - val_accuracy: 0.5798\n",
            "Epoch 151/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2553 - accuracy: 0.9168 - val_loss: 1.9315 - val_accuracy: 0.5862\n",
            "Epoch 152/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2545 - accuracy: 0.9190 - val_loss: 1.9865 - val_accuracy: 0.5720\n",
            "Epoch 153/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2440 - accuracy: 0.9193 - val_loss: 2.0935 - val_accuracy: 0.5779\n",
            "Epoch 154/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2678 - accuracy: 0.9135 - val_loss: 1.9981 - val_accuracy: 0.5751\n",
            "Epoch 155/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2576 - accuracy: 0.9180 - val_loss: 2.0698 - val_accuracy: 0.5726\n",
            "Epoch 156/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2620 - accuracy: 0.9143 - val_loss: 2.1481 - val_accuracy: 0.5874\n",
            "Epoch 157/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2618 - accuracy: 0.9156 - val_loss: 2.0345 - val_accuracy: 0.5776\n",
            "Epoch 158/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2387 - accuracy: 0.9217 - val_loss: 2.1932 - val_accuracy: 0.5723\n",
            "Epoch 159/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2416 - accuracy: 0.9214 - val_loss: 2.0982 - val_accuracy: 0.5804\n",
            "Epoch 160/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2551 - accuracy: 0.9166 - val_loss: 2.1228 - val_accuracy: 0.5701\n",
            "Epoch 161/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2549 - accuracy: 0.9184 - val_loss: 2.0553 - val_accuracy: 0.5787\n",
            "Epoch 162/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2486 - accuracy: 0.9213 - val_loss: 2.2142 - val_accuracy: 0.5692\n",
            "Epoch 163/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2574 - accuracy: 0.9187 - val_loss: 2.0238 - val_accuracy: 0.5709\n",
            "Epoch 164/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2459 - accuracy: 0.9211 - val_loss: 2.0017 - val_accuracy: 0.5754\n",
            "Epoch 165/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2333 - accuracy: 0.9257 - val_loss: 2.0547 - val_accuracy: 0.5776\n",
            "Epoch 166/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2484 - accuracy: 0.9208 - val_loss: 2.2643 - val_accuracy: 0.5723\n",
            "Epoch 167/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2474 - accuracy: 0.9198 - val_loss: 2.1122 - val_accuracy: 0.5840\n",
            "Epoch 168/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2492 - accuracy: 0.9208 - val_loss: 1.9983 - val_accuracy: 0.5759\n",
            "Epoch 169/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2544 - accuracy: 0.9191 - val_loss: 2.1303 - val_accuracy: 0.5812\n",
            "Epoch 170/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2481 - accuracy: 0.9213 - val_loss: 2.1281 - val_accuracy: 0.5829\n",
            "Epoch 171/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2396 - accuracy: 0.9231 - val_loss: 2.1570 - val_accuracy: 0.5717\n",
            "Epoch 172/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2383 - accuracy: 0.9255 - val_loss: 2.0447 - val_accuracy: 0.5782\n",
            "Epoch 173/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2564 - accuracy: 0.9187 - val_loss: 1.8842 - val_accuracy: 0.5687\n",
            "Epoch 174/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2502 - accuracy: 0.9209 - val_loss: 2.1352 - val_accuracy: 0.5726\n",
            "Epoch 175/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2600 - accuracy: 0.9179 - val_loss: 2.0018 - val_accuracy: 0.5737\n",
            "Epoch 176/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2506 - accuracy: 0.9216 - val_loss: 2.0351 - val_accuracy: 0.5748\n",
            "Epoch 177/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2395 - accuracy: 0.9239 - val_loss: 2.0535 - val_accuracy: 0.5837\n",
            "Epoch 178/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2414 - accuracy: 0.9226 - val_loss: 2.0317 - val_accuracy: 0.5782\n",
            "Epoch 179/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2434 - accuracy: 0.9248 - val_loss: 2.1451 - val_accuracy: 0.5829\n",
            "Epoch 180/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2488 - accuracy: 0.9208 - val_loss: 1.9950 - val_accuracy: 0.5651\n",
            "Epoch 181/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2424 - accuracy: 0.9235 - val_loss: 2.1577 - val_accuracy: 0.5698\n",
            "Epoch 182/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2339 - accuracy: 0.9259 - val_loss: 2.1122 - val_accuracy: 0.5768\n",
            "Epoch 183/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2426 - accuracy: 0.9232 - val_loss: 2.1497 - val_accuracy: 0.5754\n",
            "Epoch 184/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2388 - accuracy: 0.9254 - val_loss: 2.0558 - val_accuracy: 0.5807\n",
            "Epoch 185/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2348 - accuracy: 0.9253 - val_loss: 2.0653 - val_accuracy: 0.5815\n",
            "Epoch 186/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2504 - accuracy: 0.9186 - val_loss: 2.0912 - val_accuracy: 0.5642\n",
            "Epoch 187/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2436 - accuracy: 0.9225 - val_loss: 2.1899 - val_accuracy: 0.5801\n",
            "Epoch 188/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2402 - accuracy: 0.9245 - val_loss: 2.0874 - val_accuracy: 0.5751\n",
            "Epoch 189/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2451 - accuracy: 0.9235 - val_loss: 2.0465 - val_accuracy: 0.5740\n",
            "Epoch 190/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2383 - accuracy: 0.9258 - val_loss: 2.0861 - val_accuracy: 0.5704\n",
            "Epoch 191/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2308 - accuracy: 0.9296 - val_loss: 2.1168 - val_accuracy: 0.5701\n",
            "Epoch 192/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2363 - accuracy: 0.9238 - val_loss: 2.1818 - val_accuracy: 0.5695\n",
            "Epoch 193/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2458 - accuracy: 0.9227 - val_loss: 2.1283 - val_accuracy: 0.5709\n",
            "Epoch 194/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2364 - accuracy: 0.9250 - val_loss: 2.0820 - val_accuracy: 0.5729\n",
            "Epoch 195/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2310 - accuracy: 0.9254 - val_loss: 2.0277 - val_accuracy: 0.5692\n",
            "Epoch 196/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2374 - accuracy: 0.9265 - val_loss: 2.0020 - val_accuracy: 0.5709\n",
            "Epoch 197/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2284 - accuracy: 0.9278 - val_loss: 2.3088 - val_accuracy: 0.5701\n",
            "Epoch 198/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2252 - accuracy: 0.9305 - val_loss: 2.1403 - val_accuracy: 0.5662\n",
            "Epoch 199/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2392 - accuracy: 0.9256 - val_loss: 2.0782 - val_accuracy: 0.5782\n",
            "Epoch 200/200\n",
            "449/449 [==============================] - 6s 14ms/step - loss: 0.2300 - accuracy: 0.9285 - val_loss: 2.1956 - val_accuracy: 0.5720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f322fe1c748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYMFoelY0vFl",
        "colab_type": "text"
      },
      "source": [
        "### 4) Export trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtpdiUgc4Xr1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c86ba80b-b69b-4c47-913f-f82b73d6bdc1"
      },
      "source": [
        "#change directory into drive\n",
        "%cd /content/gdrive/My Drive/Emotion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Emotion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN1atfql1ls1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the  model to  use it later on\n",
        "fer_json2 = model.to_json()\n",
        "with open(\"fer2.json\", \"w\") as json_file:\n",
        "    json_file.write(fer_json2)\n",
        "model.save_weights(\"fer2.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}